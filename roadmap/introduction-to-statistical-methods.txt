Introduction to Statistical Methods

Milestone 1: Probability Fundamentals

Sample Spaces & Events: Defining outcomes, events, and set operations (union, intersection).
Axioms of Probability: The three foundational rules and their corollaries.
Conditional Probability: Calculating probability given partial information.
Independence: Mathematical definition of independent events vs. mutually exclusive events.
Bayesâ€™ Theorem: The formula for updating probabilities based on new evidence (Crucial for Naive Bayes classifiers).
Total Probability Law: Breaking down complex probabilities into conditional parts.

Milestone 2: Random Variables & Expectations

Discrete Random Variables: Probability Mass Functions (PMF) and Cumulative Distribution Functions (CDF).
Continuous Random Variables: Probability Density Functions (PDF) and integration for probabilities.
Expectation (Mean): Expected value calculations for discrete and continuous variables.
Variance & Standard Deviation: Measuring spread and dispersion in data.
Moments: Skewness and Kurtosis (shape of the distribution).
Moment Generating Functions (MGF): Using MGFs to find moments and identify distributions.

Milestone 3: Common Probability Distributions

Bernoulli & Binomial: Modeling binary outcomes and success counts.
Poisson Distribution: Modeling rates of events over time/space.
Uniform Distribution: Continuous and discrete uniform probabilities.
Normal (Gaussian) Distribution: The Bell curve, standard normal (Z), and the empirical rule.

Exponential Distribution: Modeling time until an event occurs (memoryless property).
Gamma & Beta Distributions: Flexible distributions often used as conjugate priors.

Milestone 4: Joint Distributions & Sampling

Joint PDFs/PMFs: Probabilities involving two or more random variables.
Marginal & Conditional Distributions: Extracting single-variable behavior from joint data.
Covariance & Correlation: Quantifying linear relationships between variables.
Independence of RVs: Checking if.
The Central Limit Theorem (CLT): Why averages of samples tend to be Normal (foundational for inference).
Sampling Distributions: Distribution of the sample mean and sample variance (Chi-square).

Milestone 5: Estimation Theory

Point Estimation: Using sample data to calculate a single value for a population parameter.
Properties of Estimators: Bias, Consistency, Efficiency, and Mean Squared Error (MSE).
Maximum Likelihood Estimation (MLE): Deriving parameters that maximize the likelihood function (The engine behind many ML models).
Confidence Intervals: Constructing intervals for Mean (known/unknown variance) and Proportions.
Prediction Intervals: Estimating the range for a future single observation.

Milestone 6: Hypothesis Testing

Testing Basics: Null vs. Alternative hypotheses.
Errors in Testing: Type I Error (False Positive) and Type II Error (False Negative).
Power of a Test: Probability of correctly rejecting a false null hypothesis.
Parametric Tests: Z-test and t-tests (one-sample, two-sample, paired).
P-Value Approach: Interpreting p-values for decision making.
Chi-Square Tests: Testing for Goodness of Fit and Independence (categorical data).